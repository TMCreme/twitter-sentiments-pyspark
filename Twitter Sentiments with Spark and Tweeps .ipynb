{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfb4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules \n",
    "import os\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql.functions import pandas_udf, col, udf,expr, from_json, window\n",
    "from pyspark.sql.types import FloatType, StringType, StructType\n",
    "from pyspark.sql import SparkSession\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "import findspark\n",
    "import json\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29693726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Twitter Sentiment\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = configparser.ConfigParser()\n",
    "# config.read('secrets.ini')\n",
    "# confluent_host = config['confluent_default']['bootstrap.servers']\n",
    "# confluent_username = config['confluent_default']['sasl.username']\n",
    "# confluent_password = config['confluent_default']['sasl.password']\n",
    "\n",
    "# kafka_jaas = \"\"\"kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username='{}' password='{}';\"\"\".format(confluent_username, confluent_password)\n",
    "# # confluent_consumer.update(config['confluent_consumer'])\n",
    "# print(kafka_jaas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2bf007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscribing to the kafka topic that receives the data and read from it\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"kafka_tweets_stream\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08400405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF that classifies the tweets as a positive/negative/neutral sentiment\n",
    "# Binary classification \n",
    "@udf(returnType=StringType())\n",
    "def sentiment_fxn(text: str):\n",
    "    try:\n",
    "        sent_cal = round(float(TextBlob(text).sentiment.polarity), 2)\n",
    "        if sent_cal > 0:\n",
    "            return \"Postive\"\n",
    "        elif sent_cal < 0:\n",
    "            return \"Negative\"\n",
    "        return \"Neutral\"\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timestamp = df.selectExpr(\"CAST(value as STRING)\", \"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71cdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowedCounts = df \\\n",
    "    .withWatermark(\"timestamp\", \"10 minutes\") \\\n",
    "    .groupBy(\n",
    "        window(df.timestamp, \"10 minutes\", \"5 minutes\")\n",
    "#         from_json(df.value, sample_schema).alias('sample')\n",
    "    ).count().orderBy('window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9dafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The schema of the streamed data has the expected data represented by the 'value' key\n",
    "# Using the SQL select statement to cast the binary data as string\n",
    "my_df = df.selectExpr(\"CAST(value as STRING)\", \"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected schema of the expected data\n",
    "sample_schema = (\n",
    "    StructType()\n",
    "    .add(\"created_at\", StringType())\n",
    "    .add(\"id\", StringType())\n",
    "    .add(\"id_str\" , StringType())\n",
    "    .add(\"text\", StringType())\n",
    "    .add(\"source\", StringType())\n",
    "    .add(\"truncated\", StringType())\n",
    "    .add(\"in_reply_to_status_id\", StringType())\n",
    "    .add(\"in_reply_to_status_id_str\", StringType())\n",
    "    .add(\"in_reply_to_user_id\", StringType())\n",
    "    .add(\"in_reply_to_user_id_str\", StringType())\n",
    "    .add(\"in_reply_to_screen_name\", StringType())\n",
    "    .add(\"user\", StringType())\n",
    "    .add(\"geo\", StringType())\n",
    "    .add(\"coordinates\", StringType())\n",
    "    .add(\"place\", StringType())\n",
    "    .add(\"contributors\", StringType())\n",
    "    .add(\"retweeted_status\", StringType())\n",
    "    .add(\"is_quote_status\", StringType())\n",
    "    .add(\"quote_count\", StringType())\n",
    "    .add(\"reply_count\", StringType())\n",
    "    .add(\"retweet_count\", StringType())\n",
    "    .add(\"favorite_count\", StringType())\n",
    "    .add(\"entities\", StringType())\n",
    "    .add(\"favorited\", StringType())\n",
    "    .add(\"retweeted\", StringType())\n",
    "    .add(\"possibly_sensitive\", StringType())\n",
    "    .add(\"filter_level\", StringType())\n",
    "    .add(\"lang\", StringType())\n",
    "    .add(\"timestamp_ms\", StringType())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82edcb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the schema above to apply on the data\n",
    "into_dataframe = my_df.select(\n",
    "        from_json(col(\"value\"), sample_schema).alias(\"sample\"),\n",
    "    \"timestamp\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49acd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data into a dataframe\n",
    "into_df = into_dataframe.select(\"sample.*\", \"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the classification function on the text column of the dataframe\n",
    "sent_df = into_df.withColumn(\"sentiment\", sentiment_fxn(col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a208d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an aggregate query on the df to enable wrtieStream\n",
    "# aggDF = sent_df.groupBy('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation with watermark and window\n",
    "aggDF1 = windowedCounts = sent_df \\\n",
    "    .withWatermark(\"timestamp\", \"10 minutes\") \\\n",
    "    .groupBy(\n",
    "        window(sent_df.timestamp, \"10 minutes\", \"5 minutes\"),\n",
    "        'sentiment'\n",
    "    ).count().orderBy('window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efa3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the aggregated data to memory as a table so we can perform SQL operations on it\n",
    "aggDF1.writeStream \\\n",
    "    .queryName(\"aggregates\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting all and converting to pandas df to enable plotting\n",
    "final_result = spark.sql(\"select * from aggregates\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cbc7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the aggregated table\n",
    "final_result.sort_values('window', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot as a bar graph the various sentiment values\n",
    "spark.sql(\"select sentiment, count from aggregates\").toPandas()['sentiment'].value_counts().plot.bar('sentiment', 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df497fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d42d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b761b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984e13f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf5f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aee9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a2321d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
